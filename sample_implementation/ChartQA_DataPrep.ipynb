{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Dataset Preparation**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oCIZu3vUytsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ChartQA"
      ],
      "metadata": {
        "id": "du_lD_tNywlw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiSiy8kxybJN",
        "outputId": "0f92c952-ccb3-4f5c-b60f-9c8cc807d46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ChartQA'...\n",
            "remote: Enumerating objects: 42007, done.\u001b[K\n",
            "remote: Counting objects: 100% (257/257), done.\u001b[K\n",
            "remote: Compressing objects: 100% (208/208), done.\u001b[K\n",
            "remote: Total 42007 (delta 53), reused 49 (delta 49), pack-reused 41750 (from 1)\u001b[K\n",
            "Receiving objects: 100% (42007/42007), 811.38 MiB | 24.23 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n",
            "Updating files: 100% (41865/41865), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vis-nlp/ChartQA.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your uploaded zip file\n",
        "zip_path = '/content/ChartQA/ChartQA Dataset.zip'\n",
        "\n",
        "# Destination folder\n",
        "extract_to = '/content/drive/MyDrive/ChartReader/Datasets/ChartQA/Images'\n",
        "\n",
        "# Create folder if not exists\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# Unzip\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# List extracted files\n",
        "os.listdir(extract_to)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFpr8iSezb9m",
        "outputId": "2fa766dc-d1be-4b5e-ac52-afa7ce4d19ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ChartQA Dataset']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Paths to your JSON files\n",
        "file1 = '/content/drive/MyDrive/ChartReader/Datasets/ChartQA/Images/ChartQA Dataset/train/train_augmented.json'\n",
        "file2 = '/content/drive/MyDrive/ChartReader/Datasets/ChartQA/Images/ChartQA Dataset/train/train_human.json'\n",
        "\n",
        "# Read the JSON files as DataFrames\n",
        "df1 = pd.read_json(file1)\n",
        "df2 = pd.read_json(file2)\n",
        "\n",
        "# Combine the DataFrames (row-wise or column-wise depending on structure)\n",
        "# üëâ Option 1: Combine row-wise (like stacking lists)\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "\n",
        "combined_df['imgname'] = '/content/ChartQA/ChartQA Dataset/train/png/' + combined_df['imgname']\n",
        "\n",
        "\n",
        "combined_df['file_exists'] = False\n",
        "\n",
        "# Check each path with a progress bar\n",
        "for i in tqdm(combined_df.index, desc=\"Checking file paths\"):\n",
        "    combined_df.loc[i, 'file_exists'] = os.path.exists(combined_df.loc[i, 'imgname'])\n",
        "\n",
        "# Show summary\n",
        "print(\"‚úÖ Found:\", combined_df['file_exists'].sum())\n",
        "print(\"‚ùå Not Found:\", (~combined_df['file_exists']).sum())\n",
        "\n",
        "combined_df.drop(columns=['file_exists'], inplace=True)\n",
        "\n",
        "combined_df.rename(columns={\n",
        "    'imgname': 'imagePath',\n",
        "    'query': 'input',\n",
        "    'label': 'output'\n",
        "}, inplace=True)\n",
        "\n",
        "# Define the folder and filename\n",
        "save_dir = '/content/drive/MyDrive/ChartReader/Datasets/csv/ChartQA'\n",
        "save_path = f'{save_dir}/chartqa_train.csv'\n",
        "\n",
        "# Create folder if it doesn't exist\n",
        "import os\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save as CSV\n",
        "combined_df.to_csv(save_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ File saved to: {save_path}\")"
      ],
      "metadata": {
        "id": "Y5vCZu4Bzt0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc37f36-5829-4574-df71-fd3118c554e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking file paths: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28299/28299 [00:06<00:00, 4408.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found: 28299\n",
            "‚ùå Not Found: 0\n",
            "‚úÖ File saved to: /content/drive/MyDrive/ChartReader/Datasets/csv/ChartQA/chartqa_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Paths to your JSON files\n",
        "file1 = '/content/ChartQA/ChartQA Dataset/val/val_augmented.json'\n",
        "file2 = '/content/ChartQA/ChartQA Dataset/val/val_human.json'\n",
        "\n",
        "# Read the JSON files as DataFrames\n",
        "df1 = pd.read_json(file1)\n",
        "df2 = pd.read_json(file2)\n",
        "\n",
        "# Combine the DataFrames (row-wise or column-wise depending on structure)\n",
        "# üëâ Option 1: Combine row-wise (like stacking lists)\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "\n",
        "combined_df['imgname'] = '/content/ChartQA/ChartQA Dataset/val/png/' + combined_df['imgname']\n",
        "\n",
        "\n",
        "combined_df['file_exists'] = False\n",
        "\n",
        "# Check each path with a progress bar\n",
        "for i in tqdm(combined_df.index, desc=\"Checking file paths\"):\n",
        "    combined_df.loc[i, 'file_exists'] = os.path.exists(combined_df.loc[i, 'imgname'])\n",
        "\n",
        "# Show summary\n",
        "print(\"‚úÖ Found:\", combined_df['file_exists'].sum())\n",
        "print(\"‚ùå Not Found:\", (~combined_df['file_exists']).sum())\n",
        "\n",
        "combined_df.drop(columns=['file_exists'], inplace=True)\n",
        "\n",
        "combined_df.rename(columns={\n",
        "    'imgname': 'imagePath',\n",
        "    'query': 'input',\n",
        "    'label': 'output'\n",
        "}, inplace=True)\n",
        "\n",
        "# Define the folder and filename\n",
        "save_dir = '/content/drive/MyDrive/ChartReader/Datasets/csv/ChartQA'\n",
        "save_path = f'{save_dir}/chartqa_val.csv'\n",
        "\n",
        "# Create folder if it doesn't exist\n",
        "import os\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save as CSV\n",
        "combined_df.to_csv(save_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ File saved to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAsxeQy4AvcN",
        "outputId": "726c5cd1-3e26-4231-9e93-d4043775c645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking file paths: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1920/1920 [00:00<00:00, 4435.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found: 1920\n",
            "‚ùå Not Found: 0\n",
            "‚úÖ File saved to: /content/drive/MyDrive/ChartReader/Datasets/csv/ChartQA/chartqa_val.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Paths to your JSON files\n",
        "file1 = '/content/ChartQA/ChartQA Dataset/test/test_augmented.json'\n",
        "file2 = '/content/ChartQA/ChartQA Dataset/test/test_human.json'\n",
        "\n",
        "# Read the JSON files as DataFrames\n",
        "df1 = pd.read_json(file1)\n",
        "df2 = pd.read_json(file2)\n",
        "\n",
        "# Combine the DataFrames (row-wise or column-wise depending on structure)\n",
        "# üëâ Option 1: Combine row-wise (like stacking lists)\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "\n",
        "combined_df['imgname'] = '/content/ChartQA/ChartQA Dataset/test/png/' + combined_df['imgname']\n",
        "\n",
        "\n",
        "combined_df['file_exists'] = False\n",
        "\n",
        "# Check each path with a progress bar\n",
        "for i in tqdm(combined_df.index, desc=\"Checking file paths\"):\n",
        "    combined_df.loc[i, 'file_exists'] = os.path.exists(combined_df.loc[i, 'imgname'])\n",
        "\n",
        "# Show summary\n",
        "print(\"‚úÖ Found:\", combined_df['file_exists'].sum())\n",
        "print(\"‚ùå Not Found:\", (~combined_df['file_exists']).sum())\n",
        "\n",
        "combined_df.drop(columns=['file_exists'], inplace=True)\n",
        "\n",
        "combined_df.rename(columns={\n",
        "    'imgname': 'imagePath',\n",
        "    'query': 'input',\n",
        "    'label': 'output'\n",
        "}, inplace=True)\n",
        "\n",
        "# Define the folder and filename\n",
        "save_dir = '/content/drive/MyDrive/ChartReader/Datasets/csv/ChartQA'\n",
        "save_path = f'{save_dir}/chartqa_test.csv'\n",
        "\n",
        "# Create folder if it doesn't exist\n",
        "import os\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save as CSV\n",
        "combined_df.to_csv(save_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ File saved to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-GuUfFhBCTe",
        "outputId": "e00ef498-5163-4c7c-9721-7205eab5796f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checking file paths: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2500/2500 [00:00<00:00, 3270.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found: 2500\n",
            "‚ùå Not Found: 0\n",
            "‚úÖ File saved to: /content/drive/MyDrive/ChartReader/Datasets/csv/ChartQA/chartqa_test.csv\n"
          ]
        }
      ]
    }
  ]
}